<!DOCTYPE html>
<html lang="en">
    <head>
    <meta charset="utf-8">

    

    <!-- 渲染优化 -->
    <meta name="renderer" content="webkit">
    <meta name="force-rendering" content="webkit">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="HandheldFriendly" content="True" >
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <!--icon-->

    
    
        <link rel="icon" type="image/png" sizes="16x16" href="/function%20small()%20%7B%20%5Bnative%20code%5D%20%7D">
    
    
    
    


    <!-- meta -->


<title>SparkSQL | 大白</title>


    <meta name="keywords" content="大数据, Spark">




    <!-- OpenGraph -->
 
    <meta name="description" content="SparkSQL  SparkSQL总体设计Spark SQL 总体设计如下图所示，主要包含以下几个模块  Parser Analyzer Optimizer Spark planner Code Generator  其中 Spark SQL 的核心是 Catalyst 优化器，主要有两个方向，基于规则优化（Rule Based Optimizer&#x2F;RBO）、基于代价优化（Cost Based">
<meta property="og:type" content="article">
<meta property="og:title" content="SparkSQL">
<meta property="og:url" content="http://example.com/2021/12/08/SparkSQL/index.html">
<meta property="og:site_name" content="大白">
<meta property="og:description" content="SparkSQL  SparkSQL总体设计Spark SQL 总体设计如下图所示，主要包含以下几个模块  Parser Analyzer Optimizer Spark planner Code Generator  其中 Spark SQL 的核心是 Catalyst 优化器，主要有两个方向，基于规则优化（Rule Based Optimizer&#x2F;RBO）、基于代价优化（Cost Based">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071020432.png">
<meta property="og:image" content="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071048919.png">
<meta property="og:image" content="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071057518.png">
<meta property="og:image" content="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071107043.png">
<meta property="og:image" content="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071123352.png">
<meta property="og:image" content="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071126704.png">
<meta property="og:image" content="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071128381.png">
<meta property="og:image" content="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112072233535.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201022150709791.png">
<meta property="og:image" content="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112080018242.png">
<meta property="og:image" content="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112080029425.png">
<meta property="og:image" content="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112080030934.png">
<meta property="og:image" content="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112080042047.png">
<meta property="article:published_time" content="2021-12-08T12:27:00.000Z">
<meta property="article:modified_time" content="2022-03-03T16:55:34.473Z">
<meta property="article:author" content="yajun Li">
<meta property="article:tag" content="大数据">
<meta property="article:tag" content="Spark">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071020432.png">


    
<link rel="stylesheet" href="/css/style/main.css">
 

    
    
        <link rel="stylesheet" id="hl-default-theme" href="/css/highlight/github.css" media="none" >
        
    

    
    

    
    
<link rel="stylesheet" href="/css/style/dark.css">

    
<script src="/js/darkmode.js"></script>



     
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
 

    <!-- custom head -->

<meta name="generator" content="Hexo 5.4.0"></head>

    <body>
        <div id="app">
            <header class="header">
    <div class="header__left">
        <a href="/" class="button">
            <span class="logo__text">大白</span>
        </a>
    </div>
    <div class="header__right">
        
            <div class="navbar__menus">
                
                    <a href="/" class="navbar-menu button">首页</a>
                
                    <a href="/tags/" class="navbar-menu button">标签</a>
                
                    <a href="/archives/" class="navbar-menu button">归档</a>
                
            </div>
        
        
        
    <a href="/search/" id="btn-search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" width="24" height="24" fill="currentColor" stroke="currentColor" stroke-width="32"><path d="M192 448c0-141.152 114.848-256 256-256s256 114.848 256 256-114.848 256-256 256-256-114.848-256-256z m710.624 409.376l-206.88-206.88A318.784 318.784 0 0 0 768 448c0-176.736-143.264-320-320-320S128 271.264 128 448s143.264 320 320 320a318.784 318.784 0 0 0 202.496-72.256l206.88 206.88 45.248-45.248z"></path></svg>
    </a>


        
        
    <a href="javaScript:void(0);" id="btn-toggle-dark">
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path></svg>
    </a>


        
            <a class="dropdown-icon button" id="btn-dropdown" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width='24' height='24' fill="none" stroke="currentColor" stroke-width="0.7" stroke-linecap="round" stroke-linejoin="round"><path fill="currentColor" d="M3.314,4.8h13.372c0.41,0,0.743-0.333,0.743-0.743c0-0.41-0.333-0.743-0.743-0.743H3.314c-0.41,0-0.743,0.333-0.743,0.743C2.571,4.467,2.904,4.8,3.314,4.8z M16.686,15.2H3.314c-0.41,0-0.743,0.333-0.743,0.743s0.333,0.743,0.743,0.743h13.372c0.41,0,0.743-0.333,0.743-0.743S17.096,15.2,16.686,15.2z M16.686,9.257H3.314c-0.41,0-0.743,0.333-0.743,0.743s0.333,0.743,0.743,0.743h13.372c0.41,0,0.743-0.333,0.743-0.743S17.096,9.257,16.686,9.257z"></path></svg></a>
            <div class="dropdown-menus" id="dropdown-menus">
                
                    <a href="/" class="dropdown-menu button">首页</a>
                
                    <a href="/tags/" class="dropdown-menu button">标签</a>
                
                    <a href="/archives/" class="dropdown-menu button">归档</a>
                
            </div>
        
    </div>
</header>


            <main class="main">
    

<div class="post-title">
    <h1 class="post-title__text">
        SparkSQL
    </h1>
    <div class="post-title__meta">
        <a href="/archives/2021/12/" class="post-meta__date button">2021-12-08</a>
        
 
        
    
     
    <span id="busuanzi_container_page_pv" hidden>
        <span class="separate-dot"></span>
        <span></span>
        <span id="busuanzi_value_page_pv"></span>
        <span>Views</span>
    </span>



 

 
		| 本篇文章共<span class="post-count">3.2k字</span>，预计阅读<span class="post-count">12分钟</span>
    </div>
</div>



<article class="post content-card">
    <div class="post__header"></div>
    <div class="post__content">
        <p>SparkSQL</p>
<ol>
<li><h3 id="SparkSQL总体设计"><a href="#SparkSQL总体设计" class="headerlink" title="SparkSQL总体设计"></a>SparkSQL总体设计</h3><p>Spark SQL 总体设计如下图所示，主要包含以下几个模块</p>
<ol>
<li>Parser</li>
<li>Analyzer</li>
<li>Optimizer</li>
<li>Spark planner</li>
<li>Code Generator</li>
</ol>
<p>其中 Spark SQL 的核心是 Catalyst 优化器，主要有两个方向，基于规则优化（Rule Based Optimizer/RBO）、基于代价优化（Cost Based Optimizer/CBO）</p>
<p><img src="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071020432.png" class="lazy" data-srcset="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071020432.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAABlBMVEXMzMyWlpYU2uzLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAACklEQVQImWNgAAAAAgAB9HFkpgAAAABJRU5ErkJggg==" alt="img"></p>
</li>
<li><h3 id="Parser"><a href="#Parser" class="headerlink" title="Parser"></a>Parser</h3><p>Spark SQL 语句和 DataFrame 通过 ANTLR4 生成两个类，一个 SqlBaseLexer（词法解析器）一个 SqlBaseParser（语法解析器）。使用这两个解析器将 SQL 字符串语句解析成了 ANTLR4 的 ParserTree 语法树结构，再使用 AstBuilder.scala 将 ParserTree 转换成 catalyst 表达式逻辑计划 LogicPlan。</p>
<p><img src="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071048919.png" class="lazy" data-srcset="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071048919.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAABlBMVEXMzMyWlpYU2uzLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAACklEQVQImWNgAAAAAgAB9HFkpgAAAABJRU5ErkJggg==" alt="img"></p>
</li>
<li><h3 id="Analyzer"><a href="#Analyzer" class="headerlink" title="Analyzer"></a>Analyzer</h3><p>经过第一步之后，已经有了语法树，但是语法树的组成都是一个一个的占位符，并不知到其具体代表什么，例如上图的 people、score、sum 等。这时就需要一些元信息来表达这些占位符，主要是两部分：表的 scheme 和基本的函数信息，表的 scheme 主要包括基本定义（列名、数据类型）、表的数据格式（Json、text、parqut）、表的物理位置等。基本函数信息主要指类信息。</p>
<p>Analyzer 会再次遍历语法树，对树上的每个节点继续数据类型和函数绑定，例如 people 占位符会根据元数据表信息解析为包含 age、name、id 的三列的表，people.age 会被解析为 int 的变量，sum 会被解析为特定的聚合函数等</p>
<p><img src="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071057518.png" class="lazy" data-srcset="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071057518.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAABlBMVEXMzMyWlpYU2uzLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAACklEQVQImWNgAAAAAgAB9HFkpgAAAABJRU5ErkJggg==" alt="img"></p>
<p>Spark SQL 中 Analyzer 中定义了各种 Rule（解析规则），多个性质类似的 Rule 组成一个 Batch，多个 Batch 构成一个 batches，这些 batches 会由 RuleExecutor 执行，先按一个一个 Batch 顺序执行，然后对 Batch 里面的每个 Rule 顺序执行。每个 Batch 会执行一次（Once）或多次（FixedPoint，由 spark.sql.optimizer.maxIterations 参数决定），执行过程如下：</p>
<p><img src="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071107043.png" class="lazy" data-srcset="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071107043.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAABlBMVEXMzMyWlpYU2uzLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAACklEQVQImWNgAAAAAgAB9HFkpgAAAABJRU5ErkJggg==" alt="在这里插入图片描述"></p>
<p>下面贴出了一些 Rule</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">batches</span></span>: <span class="type">Seq</span>[<span class="type">Batch</span>] = <span class="type">Seq</span>(</span><br><span class="line">    <span class="type">Batch</span>(<span class="string">&quot;Substitution&quot;</span>, fixedPoint,</span><br><span class="line">      <span class="type">CTESubstitution</span>,</span><br><span class="line">      <span class="type">WindowsSubstitution</span>,</span><br><span class="line">      <span class="type">EliminateUnions</span>,</span><br><span class="line">      <span class="keyword">new</span> <span class="type">SubstituteUnresolvedOrdinals</span>(conf)),</span><br><span class="line">    <span class="type">Batch</span>(<span class="string">&quot;Hints&quot;</span>, fixedPoint,</span><br><span class="line">      <span class="keyword">new</span> <span class="type">ResolveHints</span>.<span class="type">ResolveJoinStrategyHints</span>(conf),</span><br><span class="line">      <span class="keyword">new</span> <span class="type">ResolveHints</span>.<span class="type">ResolveCoalesceHints</span>(conf)),</span><br><span class="line">    <span class="type">Batch</span>(<span class="string">&quot;Simple Sanity Check&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">      <span class="type">LookupFunctions</span>),</span><br><span class="line">    <span class="type">Batch</span>(<span class="string">&quot;Resolution&quot;</span>, fixedPoint,</span><br><span class="line">      <span class="type">ResolveTableValuedFunctions</span> ::</span><br><span class="line">      <span class="type">ResolveNamespace</span>(catalogManager) ::</span><br><span class="line">      <span class="keyword">new</span> <span class="type">ResolveCatalogs</span>(catalogManager) ::</span><br><span class="line">      <span class="type">ResolveInsertInto</span> ::</span><br><span class="line">      <span class="type">ResolveRelations</span> :: <span class="comment">// 解析列基本数据类型等信息</span></span><br><span class="line">      <span class="type">ResolveTables</span> :: <span class="comment">// 解析表信息</span></span><br><span class="line">      <span class="type">ResolveReferences</span> ::</span><br><span class="line">      <span class="type">ResolveCreateNamedStruct</span> ::</span><br><span class="line">      <span class="type">ResolveDeserializer</span> ::</span><br><span class="line">      <span class="type">ResolveNewInstance</span> ::</span><br><span class="line">      <span class="type">ResolveUpCast</span> ::</span><br><span class="line">      <span class="type">ResolveGroupingAnalytics</span> ::</span><br><span class="line">      <span class="type">ResolvePivot</span> ::</span><br><span class="line">      <span class="type">ResolveOrdinalInOrderByAndGroupBy</span> ::</span><br><span class="line">      <span class="type">ResolveAggAliasInGroupBy</span> ::</span><br><span class="line">      <span class="type">ResolveMissingReferences</span> ::</span><br><span class="line">      <span class="type">ExtractGenerator</span> ::</span><br><span class="line">      <span class="type">ResolveGenerate</span> ::</span><br><span class="line">      <span class="type">ResolveFunctions</span> :: <span class="comment">// 解析基本函数信息，如 min，max 等等</span></span><br><span class="line">      <span class="type">ResolveAliases</span> ::</span><br><span class="line">      <span class="type">ResolveSubquery</span> :: <span class="comment">// 解析 AST 中的子查询信息</span></span><br><span class="line">      <span class="type">ResolveSubqueryColumnAliases</span> ::</span><br><span class="line">      <span class="type">ResolveWindowOrder</span> ::</span><br><span class="line">      <span class="type">ResolveWindowFrame</span> ::</span><br><span class="line">      <span class="type">ResolveNaturalAndUsingJoin</span> ::</span><br><span class="line">      <span class="type">ResolveOutputRelation</span> ::</span><br><span class="line">      <span class="type">ExtractWindowExpressions</span> ::</span><br><span class="line">      <span class="type">GlobalAggregates</span> :: <span class="comment">// 解析全局的聚合函数，比如select sum(score) from table</span></span><br><span class="line">      <span class="type">ResolveAggregateFunctions</span> ::</span><br><span class="line">      <span class="type">TimeWindowing</span> ::</span><br><span class="line">      <span class="type">ResolveInlineTables</span>(conf) ::</span><br><span class="line">      <span class="type">ResolveHigherOrderFunctions</span>(v1SessionCatalog) ::</span><br><span class="line">      <span class="type">ResolveLambdaVariables</span>(conf) ::</span><br><span class="line">      <span class="type">ResolveTimeZone</span>(conf) ::</span><br><span class="line">      <span class="type">ResolveRandomSeed</span> ::</span><br><span class="line">      <span class="type">ResolveBinaryArithmetic</span> ::</span><br><span class="line">      <span class="type">TypeCoercion</span>.typeCoercionRules(conf) ++</span><br><span class="line">      extendedResolutionRules : _*),</span><br><span class="line">    <span class="type">Batch</span>(<span class="string">&quot;Post-Hoc Resolution&quot;</span>, <span class="type">Once</span>, postHocResolutionRules: _*),</span><br><span class="line">    <span class="type">Batch</span>(<span class="string">&quot;Normalize Alter Table&quot;</span>, <span class="type">Once</span>, <span class="type">ResolveAlterTableChanges</span>),</span><br><span class="line">    <span class="type">Batch</span>(<span class="string">&quot;Remove Unresolved Hints&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">      <span class="keyword">new</span> <span class="type">ResolveHints</span>.<span class="type">RemoveAllHints</span>(conf)),</span><br><span class="line">    <span class="type">Batch</span>(<span class="string">&quot;Nondeterministic&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">      <span class="type">PullOutNondeterministic</span>),</span><br><span class="line">    <span class="type">Batch</span>(<span class="string">&quot;UDF&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">      <span class="type">HandleNullInputsForUDF</span>),</span><br><span class="line">    <span class="type">Batch</span>(<span class="string">&quot;UpdateNullability&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">      <span class="type">UpdateAttributeNullability</span>),</span><br><span class="line">    <span class="type">Batch</span>(<span class="string">&quot;Subquery&quot;</span>, <span class="type">Once</span>,</span><br><span class="line">      <span class="type">UpdateOuterReferences</span>),</span><br><span class="line">    <span class="type">Batch</span>(<span class="string">&quot;Cleanup&quot;</span>, fixedPoint,</span><br><span class="line">      <span class="type">CleanupAliases</span>)</span><br><span class="line">  )</span><br></pre></td></tr></table></figure>

<p>整体来看 Analyzer 就是完成以下工作</p>
<ul>
<li>确定最终返回字段名称以及返回类型</li>
<li>确定聚合函数</li>
<li>确定表当中获取的查询字段</li>
<li>确定过滤条件</li>
<li>确定join方式</li>
<li>确定表当中的数据来源以及分区个数</li>
</ul>
</li>
<li><h3 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h3><p>优化器是 Catalyst 的核心，分为 RBO（基于规则的优化器） 和 CBO（基于代价的优化器） 两种</p>
<p>RBO：基于规则的优化器其实就是对语法树进行一次遍历，根据模式匹配能够满足特定规则的节点，进行等价转换。因此 RBO 就是将一棵树转换成另一棵树，常见的优化规则有：下推优化、常量累加优化、列值剪裁</p>
<p>下推优化最常见的就是谓词下推，将过滤逻辑尽量靠近数据源，减少后续操作的数量</p>
<p><img src="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071123352.png" class="lazy" data-srcset="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071123352.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAABlBMVEXMzMyWlpYU2uzLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAACklEQVQImWNgAAAAAgAB9HFkpgAAAABJRU5ErkJggg==" alt="img"></p>
<p>常量累加，就是将一些常量运算直接算出结果进行替换，以免后续每条结果都要进行计算。</p>
<p><img src="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071126704.png" class="lazy" data-srcset="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071126704.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAABlBMVEXMzMyWlpYU2uzLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAACklEQVQImWNgAAAAAgAB9HFkpgAAAABJRU5ErkJggg==" alt="img"></p>
<p>列剪裁，只保留查询需要的列，不扫描那些不需要的列，例如下图中的 People，只需要 id，所以在扫描 people 之后需要将其他列进行裁剪，只留下列 id。这个优化一方面大幅度减少了网络、内存数据量消耗，另一方面对于列存数据库（Parquet）来说大大提高了扫描效率。</p>
<p><img src="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071128381.png" class="lazy" data-srcset="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112071128381.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAABlBMVEXMzMyWlpYU2uzLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAACklEQVQImWNgAAAAAgAB9HFkpgAAAABJRU5ErkJggg==" alt="img"></p>
<p>下面是常用的优化规则</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">defaultBatches</span></span>: <span class="type">Seq</span>[<span class="type">Batch</span>] = &#123;</span><br><span class="line">    <span class="keyword">val</span> operatorOptimizationRuleSet =</span><br><span class="line">      <span class="type">Seq</span>(</span><br><span class="line">        <span class="comment">// Operator push down</span></span><br><span class="line">        <span class="type">PushProjectionThroughUnion</span>,</span><br><span class="line">        <span class="type">ReorderJoin</span>,</span><br><span class="line">        <span class="type">EliminateOuterJoin</span>,</span><br><span class="line">        <span class="type">PushDownPredicates</span>, <span class="comment">// 谓词下推</span></span><br><span class="line">        <span class="type">PushDownLeftSemiAntiJoin</span>,</span><br><span class="line">        <span class="type">PushLeftSemiLeftAntiThroughJoin</span>,</span><br><span class="line">        <span class="type">LimitPushDown</span>,</span><br><span class="line">        <span class="type">ColumnPruning</span>, <span class="comment">// 列剪裁</span></span><br><span class="line">        <span class="type">InferFiltersFromConstraints</span>,</span><br><span class="line">        <span class="comment">// Operator combine</span></span><br><span class="line">        <span class="type">CollapseRepartition</span>,</span><br><span class="line">        <span class="type">CollapseProject</span>,</span><br><span class="line">        <span class="type">CollapseWindow</span>,</span><br><span class="line">        <span class="type">CombineFilters</span>,</span><br><span class="line">        <span class="type">CombineLimits</span>,</span><br><span class="line">        <span class="type">CombineUnions</span>,</span><br><span class="line">        <span class="comment">// Constant folding and strength reduction</span></span><br><span class="line">        <span class="type">TransposeWindow</span>,</span><br><span class="line">        <span class="type">NullPropagation</span>,</span><br><span class="line">        <span class="type">ConstantPropagation</span>, <span class="comment">// 常量替换</span></span><br><span class="line">        <span class="type">FoldablePropagation</span>,</span><br><span class="line">        <span class="type">OptimizeIn</span>,</span><br><span class="line">        <span class="type">ConstantFolding</span>, <span class="comment">// 常量累加</span></span><br><span class="line">        <span class="type">ReorderAssociativeOperator</span>,</span><br><span class="line">        <span class="type">LikeSimplification</span>,</span><br><span class="line">        <span class="type">BooleanSimplification</span>,</span><br><span class="line">        <span class="type">SimplifyConditionals</span>,</span><br><span class="line">        <span class="type">RemoveDispensableExpressions</span>,</span><br><span class="line">        <span class="type">SimplifyBinaryComparison</span>,</span><br><span class="line">        <span class="type">ReplaceNullWithFalseInPredicate</span>,</span><br><span class="line">        <span class="type">PruneFilters</span>,</span><br><span class="line">        <span class="type">SimplifyCasts</span>,</span><br><span class="line">        <span class="type">SimplifyCaseConversionExpressions</span>,</span><br><span class="line">        <span class="type">RewriteCorrelatedScalarSubquery</span>,</span><br><span class="line">        <span class="type">EliminateSerialization</span>,</span><br><span class="line">        <span class="type">RemoveRedundantAliases</span>,</span><br><span class="line">        <span class="type">RemoveNoopOperators</span>,</span><br><span class="line">        <span class="type">SimplifyExtractValueOps</span>,</span><br><span class="line">        <span class="type">CombineConcats</span>) ++</span><br><span class="line">        extendedOperatorOptimizationRules</span><br></pre></td></tr></table></figure></li>
<li><h3 id="SparkPlanner"><a href="#SparkPlanner" class="headerlink" title="SparkPlanner"></a>SparkPlanner</h3><p>至此，可以得到一个经过优化后的执行计划（Optimized logical plan）,但是 OLP 还没办法真正执行，只是逻辑上可行，Spark 不知道如何去执行这个 OLP。例如，join 只是一个抽象的概念，代表两个表根据相同的 id 进行合并，然而具体怎么合并，OLP 并没有说明。这时就需要将 OLP 转换为 physical plan 物理执行计划，将逻辑上可行的执行计划变为 spark 可以真正执行的计划。下图表示将一个 OLP 转换为 Physical Plan 的过程。</p>
<p><img src="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112072233535.png" class="lazy" data-srcset="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112072233535.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAABlBMVEXMzMyWlpYU2uzLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAACklEQVQImWNgAAAAAgAB9HFkpgAAAABJRU5ErkJggg==" alt="img"></p>
<p>上图可以看到，将 OLP 的一些节点都转换为 Spark 的算子，比如 join 操作，Spark 根据不同的场景为该节点算子不同的算法策略，有 BroadcastHashJoin、ShuffleHashJoin、SortMergeJoin，物理执行计划实际上就是在这些具体实现中挑选一个耗时最小的实现，这个过程就涉及到 cost base optimizer/CBO。</p>
<p>最后这个转换是由 SparkPlanner 来完成的，SparkPlanner 继承了几个抽象类，其关系如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">SparkPlanner</span> -&gt; <span class="type">SparkStrategies</span>(抽象类) -&gt; <span class="type">QueryPlanner</span>(抽象类) </span><br></pre></td></tr></table></figure>

<p>在 QueryPlanner 中实现了一个 plan() 方法，这个方法通过对一些 SparkStrategy 进行替换 OLP 中的占位符，可以将 OLP 转换为物理执行计划。SparkStrategy 主要可以分为三类：</p>
<ul>
<li><p>experimentalMethods 的 extraStrategies</p>
</li>
<li><p>extralPlanningStategies 策略，该策略列表会在 sessionState 时创建</p>
</li>
<li><p>常规策略（GenericStrategy）,这些策略都继承自 SparkStrategy，对应不同的操作，如 join、limit 等。主要有以下这些：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">experimentalMethods.extraStrategies ++</span><br><span class="line">      extraPlanningStrategies ++ (</span><br><span class="line">        <span class="comment">// 常规策略</span></span><br><span class="line">      <span class="type">DataSourceV2Strategy</span> ::</span><br><span class="line">      <span class="type">FileSourceStrategy</span> ::</span><br><span class="line">      <span class="type">DataSourceStrategy</span>(conf) ::</span><br><span class="line">      <span class="type">SpecialLimits</span> ::</span><br><span class="line">      <span class="type">Aggregation</span> ::</span><br><span class="line">      <span class="type">JoinSelection</span> ::</span><br><span class="line">      <span class="type">InMemoryScans</span> ::</span><br><span class="line">      <span class="type">BasicOperators</span> :: <span class="type">Nil</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<p>SparkPlanner 实现：</p>
<ol>
<li>通过配置（spark.sql.shuffle.partitons，默认 200）拿到 shuffle 的分区数。</li>
<li>设定 SparkStrategy，形成一个策略列表，保存到 strategies 中。</li>
<li>定义一个 prunePlans 函数，通过该函数来防止组合爆炸，需要修剪坏的计划，但是在 spark-2.3 中什么也没做，后续应该会实现。</li>
<li>提供一个 pruneFilterProject 函数，用于构建表扫描符，使用单独的物理运算符来完成复杂的映射和过滤，可能会添加 project 和 Filter 节点，主要是映射下推（列裁剪）优化</li>
</ol>
<p>SparkPlanner 的父类：SparkStrategies</p>
<p>SparkStrategies 定义了各种将 OLP 转换为物理计划的的策略，主要包含以下几种策略：</p>
<ul>
<li>limit operators：SpecialLimits</li>
<li>join operators：JoinSelection</li>
<li>streaming aggregation：StatefulAggregationStrategy</li>
<li>streaming deduplicate：StreamingDeduplicationStrategy</li>
<li>streaming join：StreamingJoinStrategy</li>
<li>aggreation：Aggregation</li>
<li>in memory scans：InMemoryScans</li>
<li>stream relation：StreamingRelationStrategy</li>
<li>FlatMapGroupsWithStateStrategy</li>
<li>基本操作（distinct、intersect 等等）：BasicOperators</li>
</ul>
<p>最上层抽象类：QueryPlanner</p>
<p>其核心就是 plan() 方法，逻辑如下：</p>
<ol>
<li><p>收集物理执行计划候选集</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> candidates = strategies.iterator.flatMap(_(plan))</span><br></pre></td></tr></table></figure></li>
<li><p>需要转换的候选集中可能包含占位符，需要用他们的自节点替换该占位符</p>
</li>
<li><p>通过 prunePlans() 方法来修剪物理执行计划，当前版本（2.3）啥也没做</p>
</li>
</ol>
<p>至此，物理执行计划就生成了，但是当前的物理执行计划并不是最优的，后续还要在 prepareForExecution 中进行优化，才能进行执行代码的生成。</p>
</li>
<li><h3 id="Code-Generator"><a href="#Code-Generator" class="headerlink" title="Code Generator"></a>Code Generator</h3><p>目前为止，Spark 已经生成一份物理执行计划，但是还不能直接执行，还需要用一些 Rule 对 SparkPlan 进行处理，也就是 prepareForExecution 过程，有如下这些 Rule。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Seq(</span><br><span class="line">    python.ExtractPythonUDFs,</span><br><span class="line">    PlanSubqueries(sparkSession),</span><br><span class="line">    EnsureRequirements(sparkSession.sessionState.conf),</span><br><span class="line">    CollapseCodegenStages(sparkSession.sessionState.conf),</span><br><span class="line">    ReuseExchange(sparkSession.sessionState.conf),</span><br><span class="line">    ReuseSubquery(sparkSession.sessionState.conf))</span><br></pre></td></tr></table></figure>

<p>CollapseCodegenStages 是核心部分，代码生成阶段。一般处理 SQL 语句都是通过一个叫 <strong>Volcano Iterator Model</strong>（参见 <a target="_blank" rel="noopener" href="http://paperhub.s3.amazonaws.com/dace52a42c07f7f8348b08dc2b186061.pdf">《Volcano-An Extensible and Parallel Query Evaluation System》</a>）的模型，在 Spark 2.0 以前就是基于这个模型处理 SQL 的，当今大多数的数据库系统处理 SQL 在底层都是基于这个模型，大概逻辑为：</p>
<ol>
<li><p>数据库引擎将 SQL 翻译成一系列的关系代数或表达式</p>
</li>
<li><p>依赖这些关系代数或着表达式逐条处理输入数据并产生结果</p>
</li>
<li><p>每个算子在底层都实现同样的接口，比如 next() 方法，然后顶层算子调用子算子的 next()，一层层调用，如下图：</p>
<p><img src="https://img-blog.csdnimg.cn/20201022150709791.png" class="lazy" data-srcset="https://img-blog.csdnimg.cn/20201022150709791.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAABlBMVEXMzMyWlpYU2uzLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAACklEQVQImWNgAAAAAgAB9HFkpgAAAABJRU5ErkJggg=="></p>
<p>Volcano Iterator Model 的优点是抽象起来很简单，容易实现，可以通过任意组合来表达复杂的查询，缺点就是性能差。<a target="_blank" rel="noopener" href="https://databricks.com/blog/2016/05/23/apache-spark-as-a-compiler-joining-a-billion-rows-per-second-on-a-laptop.html">databricks的官方博客</a>对比过使用 Volcano Iterator Model 和模拟手写代码的执行效率，结果发现模拟手写的代码执行效率要高出十倍！所以总结起来就是将 SQL 解析成为代码，比 SQL 引擎直接解析 SQL 语句效率要快，所以spark2.0 最终选择使用代码生成的方式来执行 SQL 语句。</p>
</li>
</ol>
<p>代码生成分为三部分：</p>
<ul>
<li>表达式代码生成（expression codegen）</li>
<li>全阶段代码生成（Whole-stage Code Generation）</li>
<li>代码编译</li>
</ul>
<ol>
<li><p>表达式生成</p>
<p>表达式代码生成的基类是 CodeGenerator，有七个子类</p>
<p><img src="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112080018242.png" class="lazy" data-srcset="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112080018242.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAABlBMVEXMzMyWlpYU2uzLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAACklEQVQImWNgAAAAAgAB9HFkpgAAAABJRU5ErkJggg==" alt="image-20211208001843102"></p>
<p>例如 age &gt; 10 就是最基本的表达式，也是一个 Predicate，所以会调用 GeneratePredicate 来生成表达式的代码。表达式代码生成主要是想解决大量虚函数调用（Virtual Function Calls），泛化的代价等。需要注意的是，通过表达式生成完整的类代码只有在将 <code>spark.sql.codegen.wholeStage</code> 设置为 false 才会进行的，否则只会生成一部分代码，并且和其他代码组成 Whole-stage Code。</p>
</li>
<li><p>全阶段代码生成</p>
<ul>
<li><p>全阶段代码生成，用来将多个处理逻辑整合到单个代码模块中，也会用到上面的表达式生成。不过和表达式生成不同的是，这是对整个 SQL 过程进行代码生成，表达式生成仅仅是针对表达式。</p>
<p>全阶段代码生成的代码都是继承自 BufferedRowIterator，生成的代码需要实现 processNext() 方法。processNext() 方法在 WholeStageCodegenExec 里面的 doExecute 方法里面被调用。而这个方法里面的 rdd 会将数据传进生成的代码里面。调用链如下图所示</p>
<p><img src="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112080029425.png" class="lazy" data-srcset="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112080029425.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAABlBMVEXMzMyWlpYU2uzLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAACklEQVQImWNgAAAAAgAB9HFkpgAAAABJRU5ErkJggg==" alt="在这里插入图片描述"></p>
<p>生成的代码很好理解，以 age != null and age &gt; 10 为例，其实就是对每行的 age 进行 isnotnull(age#8) &amp;&amp; (age#8 &gt; 10) 表达式判断，然后拿到符合条件的行。</p>
<p>相比之前的 Volcano Iterator Model，全阶段代码生成的执行过程如下：</p>
<p><img src="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112080030934.png" class="lazy" data-srcset="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112080030934.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAABlBMVEXMzMyWlpYU2uzLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAACklEQVQImWNgAAAAAgAB9HFkpgAAAABJRU5ErkJggg==" alt="在这里插入图片描述"></p>
</li>
</ul>
</li>
<li><p>代码编译</p>
<p>生成代码之后需要解决的另一个问题是如何将生成的代码进行编译然后加载到同一个 JVM 中去。在早期 Spark 版本是使用 Scala 的 Reflection 和 Quasiquotes 机制来实现代码生成的。Quasiquotes 是一个简洁的符号，可以让我们轻松操作 Scala 语法树，具体参见 <a target="_blank" rel="noopener" href="https://docs.scala-lang.org/overviews/quasiquotes/intro.html">这里</a>。虽然 Quasiquotes 可以很好的为我们解决代码生成等相关的问题，但是带来的新问题是编译代码时间比较长（大约 50ms - 500ms）！所以社区不得不默认关闭表达式代码生成。</p>
<p>为了解决这个问题，Spark 引入了 Janino 项目，参见 <a target="_blank" rel="noopener" href="https://issues.apache.org/jira/browse/SPARK-7956">SPARK-7956</a>。Janino 是一个超级小但又超级快的 Java™ 编译器. 它不仅能像 javac 工具那样将一组源文件编译成字节码文件，还可以对一些 Java 表达式，代码块，类中的文本(class body)或者内存中源文件进行编译，并把编译后的字节码直接加载到同一个 JVM 中运行。Janino 不是一个开发工具, 而是作为运行时的嵌入式编译器，比如作为表达式求值的翻译器或类似于 JSP 的服务端页面引擎，关于 Janino 的更多知识请参见<a target="_blank" rel="noopener" href="https://janino-compiler.github.io/janino/">这里</a>。通过引入了 Janino 来编译生成的代码，结果显示 SQL 表达式的编译时间减少到 5ms。在 Spark 中使用了 ClassBodyEvaluator 来编译生成之后的代码。</p>
<p>需要注意的是代码生成是在 Driver 端，而代码编译是在 Executor 端。</p>
</li>
</ol>
</li>
<li><h3 id="最后就是-SQL-执行了"><a href="#最后就是-SQL-执行了" class="headerlink" title="最后就是 SQL 执行了"></a>最后就是 SQL 执行了</h3></li>
<li><h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><p>本文总体讲述了在 Spark SQL 中一条 SQL 语句是如何在 Spark 中执行的，经历了 Analyzer、Optimizer、SparkPlanner 这几个流程，但还有一些点没有涉及到，例如：CBO（cost base optimizer）,后续补上。</p>
<p><img src="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112080042047.png" class="lazy" data-srcset="https://raw.githubusercontent.com/big-white-2020/notes-image/master/img/202112080042047.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABAQMAAAAl21bKAAAABlBMVEXMzMyWlpYU2uzLAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAACklEQVQImWNgAAAAAgAB9HFkpgAAAABJRU5ErkJggg==" alt="img"></p>
</li>
<li><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a target="_blank" rel="noopener" href="http://hbasefly.com/2017/03/01/sparksql-catalyst/">SparkSQL – 从0到1认识Catalyst</a></p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/410c23efb565">Spark SQL Catalyst优化器</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zg_hover/article/details/104449743">spark2 sql原理分析–逻辑计划转换成物理计划的实现分析(SparkPlanner)</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_30031221/article/details/109222355">详解Spark SQL 底层实现原理(parser、analyzer、optimizer、physical plan)</a></p>
<p> <a target="_blank" rel="noopener" href="https://www.iteblog.com/archives/2563.html">一条 SQL 在 Apache Spark 之旅（下）</a></p>
</li>
</ol>

    </div>
     
    <div class="post-footer__meta"><p>updated at 2022-03-04</p></div> 
    <div class="post-entry__tags"><a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" class="post-tags__link button"># 大数据</a><a href="/tags/Spark/" class="post-tags__link button"># Spark</a></div> 
</article>


    <div class="nav">
        <div class="nav__prev">
            
                <a href="/2022/01/09/Flink%20%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B/" class="nav__link">
                    <div>
                        <svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="24" height="24"><path d="M589.088 790.624L310.464 512l278.624-278.624 45.248 45.248L400.96 512l233.376 233.376z" fill="#808080"></path></svg>
                    </div>
                    <div>
                        <div class="nav__label">
                            Previous Post
                        </div>
                        <div class="nav__title">
                            Flink-1.14 源码分析--任务提交流程
                        </div>
                    </div>
                </a>
            
        </div>
        <div class="nav__next">
            
                <a href="/2021/12/01/Spark%20%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F1%E2%80%94%E5%9D%97%E4%BF%A1%E6%81%AF/" class="nav__link">
                    <div>
                        <div class="nav__label">
                            Next Post
                        </div>
                        <div class="nav__title">
                            Spark 存储系统1—块信息
                        </div>
                    </div>
                    <div>
                        <svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="24" height="24"><path d="M434.944 790.624l-45.248-45.248L623.04 512l-233.376-233.376 45.248-45.248L713.568 512z" fill="#808080"></path></svg>
                    </div>
                </a>
            
        </div>
    </div>



    <div class="post__comments content-card" id="comment">
        
    <h4>Comments</h4>
    
    
    
    
    
    <div id="gitalk-container"></div>

    
    
    
    
    
    


    </div>



</main>

            <footer class="footer">
     
    <a href="#" class="button" id="b2t" aria-label="Back to Top" title="Back to Top">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" width="32" height="32">
            <path d="M233.376 722.752L278.624 768 512 534.624 745.376 768l45.248-45.248L512 444.128zM192 352h640V288H192z" fill="currentColor"></path>
        </svg>
    </a>

    


    
    
    
        <span id="busuanzi_container_site_uv" hidden>
            <span></span>
            <span id="busuanzi_value_site_uv"></span>
            <span>Viewers</span>
            
                <span>|</span>
            
        </span>
    
    
        <span id="busuanzi_container_site_pv" hidden>
            <span></span>
            <span id="busuanzi_value_site_pv"></span>
            <span>Views</span>
            
        </span>
    
 
 

 
    
        
        <p class="footer-copyright">
            Copyright © 2022 <a href="/">大白</a>
        </p>
    
    
    <p>Powered by <a href="https://hexo.io" target="_blank">Hexo</a> | Theme - <a href="https://github.com/ChrAlpha/hexo-theme-cards" target="_blank">Cards</a></p>
</footer>

        </div>
        
    <script defer src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.1.0/dist/lazyload.min.js"></script>
    <script>
        window.lazyLoadOptions = {
            elements_selector: ".lazy",
            threshold: 0
        };
    </script>
 

 
    <script>
        window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
        ga('create', 'UA-178473615-1', 'auto');
        ga('send', 'pageview');
    </script>
    <script async src="https://www.google-analytics.com/analytics.js"></script>
 

 

 
    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement('script');
            hm.src = 'https://hm.baidu.com/hm.js?fb2dded415192023dd108d2b441862de';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>
 

 



 



 


    
 


    
<script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>

    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.4.1/dist/jquery.fancybox.min.css">

    
<script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.4.1/dist/jquery.fancybox.min.js"></script>

    <script>
        let lazyloadT = Boolean('true'),
            auto_fancybox = Boolean('true')
        if (auto_fancybox) {
            $(".post__content").find('img').each(function () {
                var element = document.createElement("a");
                $(element).attr("data-fancybox", "gallery");
                $(element).attr("href", $(this).attr("src"));
                if (lazyloadT) {
                    $(element).attr("href", $(this).attr("data-srcset"));
                }
                $(this).wrap(element);
            });
        } else {
            $(".post__content").find("fancybox").find('img').each(function () {
                var element = document.createElement("a");
                $(element).attr("data-fancybox", "gallery");
                $(element).attr("href", $(this).attr("src"));
                if (lazyloadT) {
                    $(element).attr("href", $(this).attr("data-srcset"));
                }
                $(this).wrap(element);
            });
        }
    </script>
 

 

 

 

 


    

    
    
    

    
    
    
    <script>
        function loadComment() {
            let e, i;
            (e = document.createElement("script")).src = 'https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js',
            document.body.appendChild(e);
            e.onload = () => {
                var gitalk = new Gitalk({
                    clientID: '5343251f7191333c2cf8',
                    clientSecret: 'c0471f2aaeafdec2f9ad0edfd4df7404db114101',
                    repo: 'big-white-2020.github.io',
                    owner: 'big-white-2020',
                    admin: 'big-white-2020',
                    id: window.location.pathname,
                    distractionFreeMode: false
                });
                gitalk.render('gitalk-container');
            };
            (i = document.createElement("link")).rel = "stylesheet",
            i.href = 'https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css',
            document.head.appendChild(i);
        }
    
        var runningOnBrowser = typeof window !== "undefined";
        var isBot = runningOnBrowser && !("onscroll" in window) || typeof navigator !== "undefined" && /(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent);
        var supportsIntersectionObserver = runningOnBrowser && "IntersectionObserver" in window;
    
        setTimeout(function () {
            if (!isBot && supportsIntersectionObserver) {
                var comment_observer = new IntersectionObserver(function(entries) {
                    if (entries[0].isIntersecting) {
                        loadComment();
                        comment_observer.disconnect();
                    }
                }, { threshold: [0] });
                comment_observer.observe(document.getElementById('comment'));
            } else {
                loadComment();
            }
        }, 1);
    </script>

    
    

    
    
    
    
    

    
    
    



    </body>
</html>
